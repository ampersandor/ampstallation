{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIA23YgbXKJd"
   },
   "source": [
    "이를 위해 pyspark과 Py4J 패키지를 설치한다. Py4J 패키지는 파이썬 프로그램이 자바가상머신상의 오브젝트들을 접근할 수 있게 해준다. Local Standalone Spark을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbT0rpGfVdiq",
    "outputId": "d66566e8-6e47-4288-aa24-dff1fb127643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: py4j\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.7\n",
      "    Uninstalling py4j-0.10.9.7:\n",
      "      Successfully uninstalled py4j-0.10.9.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyspark 3.4.0 requires py4j==0.10.9.7, but you have py4j 0.10.9.5 which is incompatible.\u001b[0m\n",
      "Successfully installed py4j-0.10.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.3.1 py4j==0.10.9.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew_eTGrvXlDw"
   },
   "source": [
    "**Spark Session**을 하나 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3vm6tgcPXdnR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/04 05:27:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Spark FS Partition Demo\") \\\n",
    "        .master(\"spark://spark-master:7077\") \\\n",
    "        .config(\"spark.executor.memory\", \"512m\")\\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKrMnuGVK77P",
    "outputId": "2655e997-ba8f-4a29-d12d-217ce3b0d1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-25 12:29:30--  https://pyspark-test-sj.s3.us-west-2.amazonaws.com/appl_stock.csv\n",
      "Resolving pyspark-test-sj.s3.us-west-2.amazonaws.com (pyspark-test-sj.s3.us-west-2.amazonaws.com)... 52.92.209.10, 52.92.149.66, 3.5.77.142, ...\n",
      "Connecting to pyspark-test-sj.s3.us-west-2.amazonaws.com (pyspark-test-sj.s3.us-west-2.amazonaws.com)|52.92.209.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 143130 (140K) [text/csv]\n",
      "Saving to: ‘appl_stock.csv.1’\n",
      "\n",
      "appl_stock.csv.1    100%[===================>] 139.78K   501KB/s    in 0.3s    \n",
      "\n",
      "2023-09-25 12:29:31 (501 KB/s) - ‘appl_stock.csv.1’ saved [143130/143130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pyspark-test-sj.s3.us-west-2.amazonaws.com/appl_stock.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark_FileSystem_Partitioning.ipynb  appl_stock.csv\n",
      "PySpark_ML_실습1.ipynb\t\t       bucketDemo.py\n",
      "PySpark_ML_실습2.ipynb\t\t       derby.log\n",
      "PySpark_Schema_Evolution.ipynb\t       join_broadcast_join\n",
      "PySpark_Write_실습.ipynb\t       wordcount\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZhdS0i7LZEc",
    "outputId": "03ec8477-4606-4e37-be36-505e1edb2e90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"appl_stock.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7g56ZGQKkRBm",
    "outputId": "4d83ab88-48ac-4230-aae0-29a96caa7d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04 00:00:00|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05 00:00:00|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06 00:00:00|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07 00:00:00|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08 00:00:00|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11 00:00:00|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12 00:00:00|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13 00:00:00|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14 00:00:00|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15 00:00:00|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vGFDiqDcLeq7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+----+-----+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|year|month|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+----+-----+\n",
      "|2010-01-04 00:00:00|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|2010|    1|\n",
      "|2010-01-05 00:00:00|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|2010|    1|\n",
      "|2010-01-06 00:00:00|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|2010|    1|\n",
      "|2010-01-07 00:00:00|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|2010|    1|\n",
      "|2010-01-08 00:00:00|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|2010|    1|\n",
      "|2010-01-11 00:00:00|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|2010|    1|\n",
      "|2010-01-12 00:00:00|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|2010|    1|\n",
      "|2010-01-13 00:00:00|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|2010|    1|\n",
      "|2010-01-14 00:00:00|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|2010|    1|\n",
      "|2010-01-15 00:00:00|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|2010|    1|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"year\", year(df.Date)) \\\n",
    "    .withColumn(\"month\", month(df.Date))\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08wqKxwmxxqp",
    "outputId": "97cc2c11-1d4e-4102-9489-77c3c52f9b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/04 05:28:59 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/10/04 05:28:59 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "23/10/04 05:29:00 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "23/10/04 05:29:00 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.21.0.2\n",
      "23/10/04 05:29:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS appl_stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wmbJXYQ0LlUB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/04 05:29:21 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "23/10/04 05:29:21 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "23/10/04 05:29:21 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/10/04 05:29:21 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "df.write.partitionBy(\"year\", \"month\").saveAsTable(\"appl_stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5bWDtHsk7lB",
    "outputId": "057bd2b6-7529-4f5f-9fc8-9f8ba0eaf3e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 412\n",
      "drwxr-xr-x 3 root root     96 Sep 25 11:57 spark-warehouse\n",
      "drwxr-xr-x 9 root root    288 Sep 25 11:56 metastore_db\n",
      "-rw-r--r-- 1 root root    723 Sep 25 11:56 derby.log\n",
      "-rw-rw-r-- 1 root root  17069 Sep 25 11:56 PySpark_FileSystem_Partitioning.ipynb\n",
      "-rw-rw-r-- 1 root root  14292 Sep 25 11:53 PySpark_Write_실습.ipynb\n",
      "drwxrwxr-x 5 root root    160 Sep 25 11:53 wordcount\n",
      "drwxr-xr-x 5 root root    160 Sep 25 11:52 dataOutput\n",
      "-rw-rw-r-- 1 root root  31964 Jul 24 04:29 PySpark_ML_실습1.ipynb\n",
      "-rw-rw-r-- 1 root root  29648 Jul 24 04:29 PySpark_ML_실습2.ipynb\n",
      "-rw-rw-r-- 1 root root  22327 Jul 24 04:29 PySpark_Schema_Evolution.ipynb\n",
      "-rw-rw-r-- 1 root root   1593 Jul 24 04:29 bucketDemo.py\n",
      "drwxrwxr-x 6 root root    192 Jul 24 04:29 join_broadcast_join\n",
      "-rw-r--r-- 1 root root 143130 Jul  6  2018 appl_stock.csv\n",
      "-rw-r--r-- 1 root root 143130 Jul  6  2018 appl_stock.csv.1\n"
     ]
    }
   ],
   "source": [
    "!ls -tl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ba_I35Ek_Na",
    "outputId": "657c90ad-d8ac-4f08-b070-e9d308ee1865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x 9 root root 4096 Jan 29 04:27 appl_stock\n"
     ]
    }
   ],
   "source": [
    "!ls -tl spark-warehouse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvBbDITnlBQB",
    "outputId": "be62ec04-4f1d-435a-9ce9-69a5efb7228f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "-rw-r--r--  1 root root   0 Sep 25 11:57  _SUCCESS\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2016'\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2015'\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2014'\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2013'\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2012'\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2011'\n",
      "drwxr-xr-x 14 root root 448 Sep 25 11:57 'year=2010'\n"
     ]
    }
   ],
   "source": [
    "!ls -tl spark-warehouse/appl_stock/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBJuOTxrlDIU",
    "outputId": "f52b04b4-01a8-4855-9a00-439cadd045e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=12'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=11'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=10'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=9'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=8'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=7'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=6'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=5'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=4'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=3'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=2'\n",
      "drwxr-xr-x 4 root root 128 Sep 25 11:57 'month=1'\n"
     ]
    }
   ],
   "source": [
    "!ls -tl spark-warehouse/appl_stock/year\\=2010/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9KESVaElIik",
    "outputId": "aa310c19-ec79-4275-fbf0-f865388e7f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw-r--r-- 1 root root 3027 Jan 29 04:27 part-00000-ee4ef65d-6e86-4c64-8880-aa44a099aad9.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -tl spark-warehouse/appl_stock/year\\=2010/month\\=12/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEp7sjYlkgs7"
   },
   "source": [
    "### How to Read from Partitioned table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JssSpbT_kgP9"
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"appl_stock\").where(\"year = 2016 and month = 12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVGLhbuZk4RH",
    "outputId": "7e25aec0-f08d-4af5-ecc6-ea59b6c73f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+----------+----------+--------+------------------+----+-----+\n",
      "|               Date|              Open|              High|       Low|     Close|  Volume|         Adj Close|year|month|\n",
      "+-------------------+------------------+------------------+----------+----------+--------+------------------+----+-----+\n",
      "|2016-12-01 00:00:00|        110.370003|        110.940002|109.029999|109.489998|37086900|        109.017344|2016|   12|\n",
      "|2016-12-02 00:00:00|109.16999799999999|        110.089996|108.849998|109.900002|26528000|        109.425578|2016|   12|\n",
      "|2016-12-05 00:00:00|             110.0|        110.029999|    108.25|109.110001|34324500|108.63898700000001|2016|   12|\n",
      "|2016-12-06 00:00:00|             109.5|        110.360001|109.190002|109.949997|26195500|109.47535800000001|2016|   12|\n",
      "|2016-12-07 00:00:00|        109.260002|        111.190002|109.160004|111.029999|29998700|        110.550697|2016|   12|\n",
      "|2016-12-08 00:00:00|        110.860001|            112.43|110.599998|112.120003|27068300|111.63599599999999|2016|   12|\n",
      "|2016-12-09 00:00:00|        112.309998|        114.699997|112.309998|113.949997|34402600|113.45808999999998|2016|   12|\n",
      "|2016-12-12 00:00:00|        113.290001|             115.0|112.489998|113.300003|26374400|        112.810902|2016|   12|\n",
      "|2016-12-13 00:00:00|        113.839996|115.91999799999999|    113.75|115.190002|43733800|        114.692743|2016|   12|\n",
      "|2016-12-14 00:00:00|        115.040001|        116.199997|114.980003|115.190002|34031800|        114.692743|2016|   12|\n",
      "+-------------------+------------------+------------------+----------+----------+--------+------------------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "090C7D5bk5DX",
    "outputId": "6d7c3df3-3e0b-45cb-9964-ea979c739544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+----------+----------+--------+------------------+----+-----+\n",
      "|               Date|              Open|              High|       Low|     Close|  Volume|         Adj Close|year|month|\n",
      "+-------------------+------------------+------------------+----------+----------+--------+------------------+----+-----+\n",
      "|2016-12-01 00:00:00|        110.370003|        110.940002|109.029999|109.489998|37086900|        109.017344|2016|   12|\n",
      "|2016-12-02 00:00:00|109.16999799999999|        110.089996|108.849998|109.900002|26528000|        109.425578|2016|   12|\n",
      "|2016-12-05 00:00:00|             110.0|        110.029999|    108.25|109.110001|34324500|108.63898700000001|2016|   12|\n",
      "|2016-12-06 00:00:00|             109.5|        110.360001|109.190002|109.949997|26195500|109.47535800000001|2016|   12|\n",
      "|2016-12-07 00:00:00|        109.260002|        111.190002|109.160004|111.029999|29998700|        110.550697|2016|   12|\n",
      "|2016-12-08 00:00:00|        110.860001|            112.43|110.599998|112.120003|27068300|111.63599599999999|2016|   12|\n",
      "|2016-12-09 00:00:00|        112.309998|        114.699997|112.309998|113.949997|34402600|113.45808999999998|2016|   12|\n",
      "|2016-12-12 00:00:00|        113.290001|             115.0|112.489998|113.300003|26374400|        112.810902|2016|   12|\n",
      "|2016-12-13 00:00:00|        113.839996|115.91999799999999|    113.75|115.190002|43733800|        114.692743|2016|   12|\n",
      "|2016-12-14 00:00:00|        115.040001|        116.199997|114.980003|115.190002|34031800|        114.692743|2016|   12|\n",
      "+-------------------+------------------+------------------+----------+----------+--------+------------------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM appl_stock WHERE year = 2016 and month = 12\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwait..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM appl_stock WHERE year = 2016 and month = 12\").show(10)\n",
    "input(\"wait..\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
